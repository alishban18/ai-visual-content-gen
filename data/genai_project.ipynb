{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Extracting a ZIP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted to: C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# First, let's verify the file location\n",
    "def extract_zip(zip_filename, download_dir, extract_to):\n",
    "    # Construct full path to zip file\n",
    "    zip_path = os.path.join(download_dir, zip_filename)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"ZIP file not found at: {zip_path}\")\n",
    "        # List files in download directory\n",
    "        print(\"\\nFiles in download directory:\")\n",
    "        for file in os.listdir(download_dir):\n",
    "            print(file)\n",
    "        return False\n",
    "    \n",
    "    # Create extraction directory if it doesn't exist\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    # Extract the ZIP file\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Successfully extracted to: {extract_to}\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"The file is not a valid ZIP file\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "download_dir = r\"C:\\Users\\Nexgen\\Downloads\"  # Main downloads directory\n",
    "zip_filename = \"unsplash-research-dataset-lite-latest.zip\"  # ZIP file name\n",
    "extract_to = r\"C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\"  # Extraction directory\n",
    "\n",
    "success = extract_zip(zip_filename, download_dir, extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Listing Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of directory: C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\n",
      "[Folder] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\collections.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\colors.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\conversions.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\DOCS.md\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\keywords.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\photos.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\README.md\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\TERMS.md\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\\._collections.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\\._colors.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\\._conversions.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\\._keywords.tsv000\n",
      "[File] C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\__MACOSX\\._photos.tsv000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files_and_folders(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory not found: {directory}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Contents of directory: {directory}\")\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Print subdirectories\n",
    "        for dir_name in dirs:\n",
    "            print(f\"[Folder] {os.path.join(root, dir_name)}\")\n",
    "        # Print files\n",
    "        for file_name in files:\n",
    "            print(f\"[File] {os.path.join(root, file_name)}\")\n",
    "\n",
    "# Usage\n",
    "unzipped_dir = r\"C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\"  # Replace with the unzipped directory path\n",
    "list_files_and_folders(unzipped_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Previewing .TSV Files\n",
    "This Python script defines a function `preview_tsv_files` to preview the first five rows of multiple `.tsv000` files from a specified directory. It uses `pandas` for data loading and displays the top rows for each file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of collections.tsv000:\n",
      "      photo_id collection_id    collection_title          photo_collected_at\n",
      "0  --2IBUMom1I       1230101              Travel  2017-09-27 11:24:17.575047\n",
      "1  --2IBUMom1I       9832457            business  2020-04-04 14:26:10.506402\n",
      "2  --2IBUMom1I       2143051     Travel / Places  2018-05-22 23:20:05.898545\n",
      "3  --2IBUMom1I   FBJEaBSjBvg            Settings  2022-06-04 03:56:40.892078\n",
      "4  --2IBUMom1I        162470  Majestical Sunsets  2016-03-15 17:04:25.089589\n",
      "\n",
      "Preview of colors.tsv000:\n",
      "      photo_id     hex  red  green  blue         keyword  ai_coverage  \\\n",
      "0  XDPk8ndzNho  5B534C   91     83    76  darkolivegreen     0.065067   \n",
      "1  IfL3QovlAbI  371511   55     21    17           black     0.105533   \n",
      "2  GKzgF32piaE  8ACCD5  138    204   213         skyblue     0.044867   \n",
      "3  T5WR9adosj8  A59A99  165    154   153        darkgray     0.050800   \n",
      "4  T5WR9adosj8  7F7575  127    117   117            gray     0.050533   \n",
      "\n",
      "   ai_score  \n",
      "0  0.030752  \n",
      "1  0.203291  \n",
      "2  0.128655  \n",
      "3  0.048626  \n",
      "4  0.030054  \n",
      "\n",
      "Preview of conversions.tsv000:\n",
      "              converted_at conversion_type                 keyword  \\\n",
      "0  2023-05-09 11:03:40.445        download                    Mond   \n",
      "1  2023-05-09 11:12:05.109        download       16.9 camel desert   \n",
      "2  2023-05-09 11:17:33.417        download                    bird   \n",
      "3  2023-05-09 11:32:03.943        download               night sky   \n",
      "4  2023-05-09 11:36:56.557        download  zoom background office   \n",
      "\n",
      "      photo_id                     anonymous_user_id conversion_country  \n",
      "0  jlV2k_Fx0fc  4589085a-75df-417b-93de-22adf2fc627d                 DE  \n",
      "1  yNGQ830uFB4  e05af0fe-4930-421d-b20d-f904f316e2c3                 CN  \n",
      "2  BFsm5vldl2I  64fd6739-db67-46e0-99f2-022efb498447                 RU  \n",
      "3  -cKXtsJWU-I  2f9c6ac4-02c8-4d0f-82b3-0482a82ab0bf                 IN  \n",
      "4  CEeoDFpVxxw  a7abbff5-4a50-4c65-b463-18139e2978e9                 IN  \n",
      "\n",
      "Preview of keywords.tsv000:\n",
      "      photo_id   keyword  ai_service_1_confidence  ai_service_2_confidence  \\\n",
      "0  zzwTUqvzIFg      rock                15.485713                      NaN   \n",
      "1  zzwTUqvzIFg     cross                19.598213                      NaN   \n",
      "2  zzwTUqvzIFg  eruption                34.787167                      NaN   \n",
      "3  zzwTUqvzIFg    sunset                30.080654                      NaN   \n",
      "4  zzwTUqvzIFg   eclipse                39.832775                      NaN   \n",
      "\n",
      "  suggested_by_user  \n",
      "0                 f  \n",
      "1                 f  \n",
      "2                 f  \n",
      "3                 f  \n",
      "4                 f  \n",
      "\n",
      "Preview of photos.tsv000:\n",
      "      photo_id                                photo_url  \\\n",
      "0  bygTaBey1Xk  https://unsplash.com/photos/bygTaBey1Xk   \n",
      "1  gXSFnk2a9V4  https://unsplash.com/photos/gXSFnk2a9V4   \n",
      "2  grg6-DNJuaU  https://unsplash.com/photos/grg6-DNJuaU   \n",
      "3  sO42hhChB1c  https://unsplash.com/photos/sO42hhChB1c   \n",
      "4  tkk8_HakQ98  https://unsplash.com/photos/tkk8_HakQ98   \n",
      "\n",
      "                                     photo_image_url  \\\n",
      "0  https://images.unsplash.com/uploads/1413387620...   \n",
      "1  https://images.unsplash.com/reserve/jEs6K0y1Sb...   \n",
      "2  https://images.unsplash.com/uploads/1412192004...   \n",
      "3  https://images.unsplash.com/reserve/ijl3tATFRp...   \n",
      "4  https://images.unsplash.com/reserve/6vaWXsQuSW...   \n",
      "\n",
      "           photo_submitted_at photo_featured  photo_width  photo_height  \\\n",
      "0  2014-10-15 15:40:40.111061              t         4635          3070   \n",
      "1         2014-07-10 18:36:06              t         2448          3264   \n",
      "2  2014-10-01 19:33:56.393181              t         5184          3456   \n",
      "3         2014-08-19 21:15:40              t         4896          3264   \n",
      "4         2014-05-05 18:31:06              t         2000          1333   \n",
      "\n",
      "   photo_aspect_ratio      photo_description photographer_username  ...  \\\n",
      "0                1.51                    NaN      jaspervandermeij  ...   \n",
      "1                0.75         Coastline view      kimberlyrichards  ...   \n",
      "2                1.50                    NaN         marcusdallcol  ...   \n",
      "3                1.50      Hazy Ocean Waters          arturpokusin  ...   \n",
      "4                1.50  Silhouettes In Desert                carlov  ...   \n",
      "\n",
      "  photo_location_country photo_location_city stats_views stats_downloads  \\\n",
      "0                    NaN                 NaN     1708356           19085   \n",
      "1          United States           Tillamook     9895033           74702   \n",
      "2                    NaN                 NaN     8967968           38338   \n",
      "3                    NaN                 NaN     2071752           10860   \n",
      "4                    NaN                 NaN     2720281            9081   \n",
      "\n",
      "                                     ai_description  ai_primary_landmark_name  \\\n",
      "0  sea and rock cliff with grasses under cloudy sky               Neist Point   \n",
      "1                    aerial photography of seashore                       NaN   \n",
      "2     man surfboarding on ocean wave during daytime                       NaN   \n",
      "3                                     body of water                       NaN   \n",
      "4                       car on desert during sunset                       NaN   \n",
      "\n",
      "   ai_primary_landmark_latitude ai_primary_landmark_longitude  \\\n",
      "0                     57.428387                     -6.783028   \n",
      "1                           NaN                           NaN   \n",
      "2                           NaN                           NaN   \n",
      "3                           NaN                           NaN   \n",
      "4                           NaN                           NaN   \n",
      "\n",
      "  ai_primary_landmark_confidence                     blur_hash  \n",
      "0                      30.348906  LcE{wnIVRixt~WR+NGjbxukCWBWB  \n",
      "1                            NaN  LXE4G#IARjj]GdWFxaWBDOxaofj[  \n",
      "2                            NaN  LcHx?5R%Rjof01bHWBof4ooMoeax  \n",
      "3                            NaN  LyOzVsj[aefQ_4j[ayj[IUayj[ay  \n",
      "4                            NaN  LYEV]I%19ZR+-=s,RkWW00WB%2j[  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def preview_tsv_files(directory, file_list):\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if file_name.endswith(\".tsv000\"):\n",
    "            try:\n",
    "                # Load the TSV file\n",
    "                print(f\"\\nPreview of {file_name}:\")\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", nrows=5)  # Load first 5 rows\n",
    "                print(df.head())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "# List of TSV files\n",
    "tsv_files = [\n",
    "    \"collections.tsv000\",\n",
    "    \"colors.tsv000\",\n",
    "    \"conversions.tsv000\",\n",
    "    \"keywords.tsv000\",\n",
    "    \"photos.tsv000\",\n",
    "]\n",
    "\n",
    "# Usage\n",
    "preview_tsv_files(r\"C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\", tsv_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Chunk-wise Merging of Large TSV Files\n",
    "This Python script processes large `.tsv000` files in chunks and performs a merge operation. It uses `pandas` for efficient data handling, especially useful when dealing with files that exceed memory capacity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define paths to the data files\n",
    "data_dir = r\"C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\" \n",
    "photos_file = os.path.join(data_dir, \"photos.tsv000\")\n",
    "collections_file = os.path.join(data_dir, \"collections.tsv000\")\n",
    "\n",
    "# Define the chunk size (adjust based on your system's capacity)\n",
    "chunk_size = 100000  # Adjust based on your system's memory\n",
    "\n",
    "# Output file for merged data\n",
    "output_file = os.path.join(data_dir, \"merged_data.csv\")\n",
    "\n",
    "# Process the photos file in chunks\n",
    "with pd.read_csv(photos_file, sep=\"\\t\", chunksize=chunk_size) as photos_reader:\n",
    "    for photos_chunk in photos_reader:\n",
    "        # Read the collections file for each chunk\n",
    "        collections = pd.read_csv(collections_file, sep=\"\\t\")\n",
    "        \n",
    "        # Merge the chunk with the collections data\n",
    "        chunk_merged = photos_chunk.merge(collections, on=\"photo_id\", how=\"left\")\n",
    "        \n",
    "        # Append the merged chunk to the output file\n",
    "        chunk_merged.to_csv(output_file, mode='a', index=False, header=not os.path.exists(output_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Efficient Large-Scale Data Merging Using Dask\n",
    "This Python script demonstrates how to use Dask, a parallel computing library, to handle large `.tsv000` files for merging operations. Dask provides an efficient way to work with large datasets that may not fit into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/photos.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/collections.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/photos.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n",
      "DEBUG:fsspec.local:open file: //?/C:/Users/Nexgen/Downloads/genAI_project_dataset/colors.tsv000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved merged result to: C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\merged_result.csv\n",
      "\n",
      "First few rows of the merged data:\n",
      "      photo_id                                photo_url  \\\n",
      "0  3OeUD6_-I4I  https://unsplash.com/photos/3OeUD6_-I4I   \n",
      "1  3OeUD6_-I4I  https://unsplash.com/photos/3OeUD6_-I4I   \n",
      "2  3OeUD6_-I4I  https://unsplash.com/photos/3OeUD6_-I4I   \n",
      "3  3OeUD6_-I4I  https://unsplash.com/photos/3OeUD6_-I4I   \n",
      "4  3OeUD6_-I4I  https://unsplash.com/photos/3OeUD6_-I4I   \n",
      "\n",
      "                                     photo_image_url  \\\n",
      "0  https://images.unsplash.com/photo-1544918334-2...   \n",
      "1  https://images.unsplash.com/photo-1544918334-2...   \n",
      "2  https://images.unsplash.com/photo-1544918334-2...   \n",
      "3  https://images.unsplash.com/photo-1544918334-2...   \n",
      "4  https://images.unsplash.com/photo-1544918334-2...   \n",
      "\n",
      "           photo_submitted_at photo_featured  photo_width  photo_height  \\\n",
      "0  2018-12-16 00:02:59.709851              t       8192.0        5461.0   \n",
      "1  2018-12-16 00:02:59.709851              t       8192.0        5461.0   \n",
      "2  2018-12-16 00:02:59.709851              t       8192.0        5461.0   \n",
      "3  2018-12-16 00:02:59.709851              t       8192.0        5461.0   \n",
      "4  2018-12-16 00:02:59.709851              t       8192.0        5461.0   \n",
      "\n",
      "   photo_aspect_ratio photo_description photographer_username  ...  \\\n",
      "0                 1.5    patrick hendry    worldsbetweenlines  ...   \n",
      "1                 1.5    patrick hendry    worldsbetweenlines  ...   \n",
      "2                 1.5    patrick hendry    worldsbetweenlines  ...   \n",
      "3                 1.5    patrick hendry    worldsbetweenlines  ...   \n",
      "4                 1.5    patrick hendry    worldsbetweenlines  ...   \n",
      "\n",
      "  collection_id collection_title         photo_collected_at     hex    red  \\\n",
      "0        772342             Dark  2017-04-21 11:22:12.08655  565656   86.0   \n",
      "1        772342             Dark  2017-04-21 11:22:12.08655  111111   17.0   \n",
      "2        772342             Dark  2017-04-21 11:22:12.08655  797979  121.0   \n",
      "3        772342             Dark  2017-04-21 11:22:12.08655  939393  147.0   \n",
      "4        772342             Dark  2017-04-21 11:22:12.08655  393939   57.0   \n",
      "\n",
      "   green   blue         keyword ai_coverage  ai_score  \n",
      "0   86.0   86.0         dimgray    0.185133  0.292294  \n",
      "1   17.0   17.0           black    0.438800  0.001822  \n",
      "2  121.0  121.0            gray    0.054667  0.331260  \n",
      "3  147.0  147.0  lightslategray    0.019467  0.245409  \n",
      "4   57.0   57.0   darkslategray    0.301933  0.129216  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Enable verbose logging for Dask\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Specify the directory where your TSV files are located\n",
    "data_dir = r\"C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\"\n",
    "\n",
    "# Construct full file paths with long path prefix (if needed)\n",
    "photos_path = r\"\\\\?\\C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\photos.tsv000\"\n",
    "collections_path = r\"\\\\?\\C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\collections.tsv000\"\n",
    "colors_path = r\"\\\\?\\C:\\Users\\Nexgen\\Downloads\\genAI_project_dataset\\colors.tsv000\"\n",
    "\n",
    "# Define dtypes for problematic columns\n",
    "dtypes = {\n",
    "    'exif_aperture_value': 'object',\n",
    "    'exif_focal_length': 'object'\n",
    "}\n",
    "\n",
    "# Load the TSV files using Dask with specified dtypes\n",
    "try:\n",
    "    photos = dd.read_csv(\n",
    "        photos_path,\n",
    "        delimiter=\"\\t\",\n",
    "        assume_missing=True,\n",
    "        blocksize=\"16MB\",  # Reduced blocksize to avoid memory issues\n",
    "        dtype=dtypes\n",
    "    )\n",
    "    \n",
    "    collections = dd.read_csv(\n",
    "        collections_path,\n",
    "        delimiter=\"\\t\",\n",
    "        assume_missing=True,\n",
    "        blocksize=\"16MB\"  # Reduced blocksize to avoid memory issues\n",
    "    )\n",
    "    \n",
    "    colors = dd.read_csv(\n",
    "        colors_path,\n",
    "        delimiter=\"\\t\",\n",
    "        assume_missing=True,\n",
    "        blocksize=\"16MB\"  # Reduced blocksize to avoid memory issues\n",
    "    )\n",
    "\n",
    "    # Perform the merge operation\n",
    "    merged_df = photos.merge(collections, on=\"photo_id\", how=\"left\")\n",
    "    merged_df = merged_df.merge(colors, on=\"photo_id\", how=\"left\")\n",
    "\n",
    "    # Compute the result using 'threads' scheduler for better performance\n",
    "    result = merged_df.compute(scheduler='threads')\n",
    "\n",
    "    # Save the result\n",
    "    output_path = os.path.join(data_dir, \"merged_result.csv\")\n",
    "    result.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Successfully saved merged result to: {output_path}\")\n",
    "    print(\"\\nFirst few rows of the merged data:\")\n",
    "    print(result.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    # Print memory usage information\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    print(\"\\nCurrent memory usage:\")\n",
    "    print(f\"Memory used: {process.memory_info().rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    # If there's an error, let's examine the structure of the files\n",
    "    print(\"\\nExamining file structure:\")\n",
    "    import pandas as pd\n",
    "    \n",
    "    try:\n",
    "        # Read just a few rows to examine structure\n",
    "        print(\"\\nPhotos file structure:\")\n",
    "        photos_sample = pd.read_csv(photos_path, delimiter=\"\\t\", nrows=5)\n",
    "        print(photos_sample.dtypes)\n",
    "        \n",
    "        print(\"\\nCollections file structure:\")\n",
    "        collections_sample = pd.read_csv(collections_path, delimiter=\"\\t\", nrows=5)\n",
    "        print(collections_sample.dtypes)\n",
    "        \n",
    "        print(\"\\nColors file structure:\")\n",
    "        colors_sample = pd.read_csv(colors_path, delimiter=\"\\t\", nrows=5)\n",
    "        print(colors_sample.dtypes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while examining file structure: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
